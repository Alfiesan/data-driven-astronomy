{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% cod"
        }
      },
      "source": "import numpy as np\nimport pydotplus as pydotplus\nfrom sklearn.tree import DecisionTreeRegressor, export_graphviz",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1\n",
        "\n",
        "Write a `get_features_targets` function that splits the training data into input features and their corresponding targets. In our case, the inputs are the 4 colour indices and our targets are the corresponding redshifts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[[0.31476 0.0571  0.28991 0.07192]\n [1.2002  0.82026 0.45294 0.24665]]\n[0.539301  0.1645703]\n"
          ],
          "metadata": {},
          "output_type": "stream"
        }
      ],
      "source": "def get_features_targets(data):\n    features \u003d np.zeros((data.shape[0], 4))\n    features[:, 0] \u003d data[\u0027u\u0027] - data[\u0027g\u0027]\n    features[:, 1] \u003d data[\u0027g\u0027] - data[\u0027r\u0027]\n    features[:, 2] \u003d data[\u0027r\u0027] - data[\u0027i\u0027]\n    features[:, 3] \u003d data[\u0027i\u0027] - data[\u0027z\u0027]\n    \n    return features, data[\u0027redshift\u0027]\n\n\ndef main():\n    data \u003d np.load(\u0027data1/sdss_galaxy_colors.npy\u0027)\n    features, targets \u003d get_features_targets(data)\n\n    print(features[:2])\n    print(targets[:2])\n\n\nif __name__ \u003d\u003d \"__main__\":\n    main()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[0.539301   0.1645703  0.04190006 0.04427702]\n"
          ],
          "metadata": {},
          "output_type": "stream"
        }
      ],
      "source": "def main():\n    # load the data and generate the features and targets\n    data \u003d np.load(\u0027data1/sdss_galaxy_colors.npy\u0027)\n    features, targets \u003d get_features_targets(data)\n\n    # initialize model\n    dtr \u003d DecisionTreeRegressor()\n    \n    # train the model\n    dtr.fit(features, targets)\n    \n    # make predictions using the same features\n    predictions \u003d dtr.predict(features)\n    \n    # print out the first 4 predicted redshifts\n    print(predictions[:4])\n\n\nif __name__ \u003d\u003d \u0027__main__\u0027:\n    main()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3\n",
        "\n",
        "In this problem we will implement the function `median_diff`. The function should calculate the median residual error of our model, i.e. the median difference between our predicted and actual redshifts.\n",
        "\n",
        "The `median_diff` function takes two arguments â€“ the predicted and actual/target values. When we use this function later in the tutorial, these will corresponding to the predicted redshifts from our decision tree and their corresponding measured/target values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": "def median_diff(predicted, actual):\n    return np.median(np.abs(predicted - actual))\n\n\ndef main():\n    targets \u003d np.load(\u0027data1/targets.npy\u0027)\n    predictions \u003d np.load(\u0027data1/predictions.npy\u0027)\n    diff \u003d median_diff(predictions, targets)\n    print(\"Median difference: {:0.3f}\".format(diff))\n\n\n# The data wasn\u0027t provided\nif __name__ \u003d\u003d \"__tbd__\":\n    main()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 4\n",
        "\n",
        "In this problem, we will use `median_diff` from the previous question to validate the decision tree model. Your task is to complete the `validate_model` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Median difference: 0.021800\n"
          ],
          "metadata": {},
          "output_type": "stream"
        }
      ],
      "source": "# write a function that splits the data into training and testing subsets\n# trains the model and returns the prediction accuracy with median_diff\ndef validate_model(model, features, targets):\n    # split the data into training and testing features and predictions\n    split \u003d 2*features.shape[0]//3\n    train_features \u003d features[:split]\n    test_features \u003d features[split:]\n    \n    train_targets \u003d targets[:split]\n    test_targets \u003d targets[split:]\n\n    # train the model\n    model.fit(train_features, train_targets)\n\n    # get the predicted_redshifts\n    predictions \u003d model.predict(test_features)\n  \n    # use median_diff function to calculate the accuracy\n    return median_diff(test_targets, predictions)\n\n\ndef main():\n    data \u003d np.load(\u0027data1/sdss_galaxy_colors.npy\u0027)\n    features, targets \u003d get_features_targets(data)\n\n    # initialize model\n    dtr \u003d DecisionTreeRegressor()\n\n    # validate the model and print the med_diff\n    diff \u003d validate_model(dtr, features, targets)\n    print(\u0027Median difference: {:f}\u0027.format(diff))\n\n\nif __name__ \u003d\u003d \"__main__\":\n    main()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot the decision tree (optional activity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": "def main():\n    data \u003d np.load(\u0027data1/sdss_galaxy_colors.npy\u0027)\n    features, targets \u003d get_features_targets(data)\n\n    # Initialize model\n    dtr \u003d DecisionTreeRegressor(max_depth\u003d3)    # We will come to this input in the next tutorial\n\n    # Split the data into training and testing\n    split_index \u003d int(0.5 * len(features))\n    train_features \u003d features[:split_index]\n    train_targets \u003d targets[:split_index]\n\n    dtr.fit(train_features, train_targets)\n\n    dot_data \u003d export_graphviz(dtr, out_file\u003dNone,feature_names\u003d[\u0027u - g\u0027, \u0027g - r\u0027, \u0027r - i\u0027, \u0027i - z\u0027])\n    graph \u003d pydotplus.graph_from_dot_data(dot_data)\n    graph.write_jpg(\"decision_tree.jpg\")\n\n\nif __name__ \u003d\u003d \"__main__\":\n    main()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}